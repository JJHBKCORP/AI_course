{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBjXt/1qwXrKhbAP2FwRD/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjhbk/AI_course/blob/main/QLeaerning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7fUkhkcNGN1",
        "outputId": "91348778-1e2e-46a2-aabe-c82bc1372235"
      },
      "source": [
        "import numpy as np \n",
        "gamma = 0.75;\n",
        "alpha=0.9;\n",
        "location_to_state={'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11};\n",
        "actions=[0,1,2,3,4,5,6,7,8,9,10,11];\n",
        "R=np.array([[0,1,0,0,0,0,0,0,0,0,0,0],\n",
        "[1,0,1,0,0,1,0,0,0,0,0,0],\n",
        "[0,1,0,0,0,0,1,0,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,1,0,0,0,0],\n",
        "[0,0,0,0,0,0,0,0,1,0,0,0],\n",
        "[0,1,0,0,0,0,0,0,0,1,0,0],\n",
        "[0,0,1,0,0,0,1000,1,0,0,0,0],\n",
        "[0,0,0,1,0,0,1,0,0,0,0,1],\n",
        "[0,0,0,0,1,0,0,0,0,1,0,0],\n",
        "[0,0,0,0,0,1,0,0,1,0,1,0],\n",
        "[0,0,0,0,0,0,0,0,0,1,0,1],\n",
        "[0,0,0,0,0,0,0,1,0,0,1,0]]);\n",
        "Q=np.array(np.zeros([12,12]));\n",
        "for i in range(1000):\n",
        "  current_state= np.random.randint(0,12);\n",
        "  playable_actions= [];\n",
        "  for j in range (12):\n",
        "    if R[current_state,j] > 0:\n",
        "      playable_actions.append(j);\n",
        "  next_state=np.random.choice(playable_actions);\n",
        "  TD = R[current_state, next_state] + gamma * Q[next_state,np.argmax(Q[next_state,])] - Q[current_state, next_state];\n",
        "  Q[current_state, next_state] = Q[current_state, next_state] +alpha * TD;\n",
        " # TD=R[current_state,next_state]+gamma*Q[current_state,np.argmax(Q[next_state,])-Q[current_state,next_state]];\n",
        "  #Q[current_state,next_state]=Q[current_state,next_state]+alpha*TD;\n",
        "print(\"Q-values:\")\n",
        "print(Q.astype(int));"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-values:\n",
            "[[   0 1689    0    0    0    0    0    0    0    0    0    0]\n",
            " [1267    0 2250    0    0 1267    0    0    0    0    0    0]\n",
            " [   0 1688    0    0    0    0 2999    0    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0 2250    0    0    0    0]\n",
            " [   0    0    0    0    0    0    0    0  714    0    0    0]\n",
            " [   0 1688    0    0    0    0    0    0    0  951    0    0]\n",
            " [   0    0 2250    0    0    0 3999 2250    0    0    0    0]\n",
            " [   0    0    0 1689    0    0 2999    0    0    0    0 1688]\n",
            " [   0    0    0    0  536    0    0    0    0  951    0    0]\n",
            " [   0    0    0    0    0 1267    0    0  710    0 1267    0]\n",
            " [   0    0    0    0    0    0    0    0    0  951    0 1689]\n",
            " [   0    0    0    0    0    0    0 2250    0    0 1267    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgSpUYHBTlEI"
      },
      "source": [
        "\n",
        "for i in range(1000):\n",
        "current_state = np.random.randint(0,12)\n",
        "playable_actions = []\n",
        "for j in range(12):\n",
        "if R[current_state, j] > 0:\n",
        "playable_actions.append(j)\n",
        "next_state = np.random.choice(playable_actions)\n",
        "TD = R[current_state, next_state] + gamma * Q[next_state,\n",
        "np.argmax(Q[next_state,])] - Q[current_state, next_state]\n",
        "Q[current_state, next_state] = Q[current_state, next_state] +\n",
        "alpha * TD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vg3pmHseKns"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmUC0jgobpD9"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbgIoGRMbqNk"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}